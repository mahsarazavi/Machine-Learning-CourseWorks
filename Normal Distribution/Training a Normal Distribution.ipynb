{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw4_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUXoMKBNL2BB",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<h3 align=\"center\">به نام خدا </h3>\n",
        "<h2 align=\"center\">تمرین سری چهارم </h2>\n",
        "\n",
        "\n",
        "<p align=\"right\">در این تمرین می خواهیم با کمک دانسته های خود از توزیع نرمال یک متغیره یک دسته بند طراحی کنیم</p>\n",
        "\n",
        "<p align=\"right\">برای پیاده سازی مدل ها از کتابخانه  استفاده کنید scikitlearn</p>\n",
        "\n",
        "<p align=\"right\">https://scikit-learn.org/stable/</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzYY1KuUPu2Z",
        "colab_type": "text"
      },
      "source": [
        "# خواندن داده ها"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0v0tV8s9P4xZ",
        "colab_type": "text"
      },
      "source": [
        "<p align=\"right\">ابتدا داده ها را از کتابخانه می خوانیم و سپس داده ها را به دو دسته ی آموزش و آزمایش تقسیم بندی می کنیم</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wyhQpoQQgQ0",
        "colab_type": "code",
        "outputId": "7d3a8be3-0a56-4194-83a6-bd6182783ce4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# store the feature matrix (X) and response vector (y) \n",
        "X = iris.data\n",
        "y = iris.target\n",
        "print(\"our dataset has \" + str(X.shape[1]) + \" features. for more information about data surf the web\")\n",
        "# splitting X and y into training and testing sets\n",
        "#you can change the test size, fit model with more or less data and see results\n",
        "from sklearn.model_selection import train_test_split \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1) \n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "our dataset has 4 features. for more information about data surf the web\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq4rKK30R9fz",
        "colab_type": "text"
      },
      "source": [
        "### q1) print the number of train and test data and number of classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQy7kw4pSR8l",
        "colab_type": "code",
        "outputId": "4e44e2c3-6b5b-44bc-aa3c-a0282299bf75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "print(\"the number of train data is : \", len(X_train))\n",
        "print(\"the number of test data is : \", len(X_test))\n",
        "print(\"there is \" + str() + \" different classes in the dataset\", len(np.unique(y_train)))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the number of train data is :  90\n",
            "the number of test data is :  60\n",
            "there is  different classes in the dataset 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDB-hbPVSpHt",
        "colab_type": "text"
      },
      "source": [
        "# آموزش یک مدل با فرض گوسی بودن توزیع داد ها"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nqd2cq44Tksm",
        "colab_type": "text"
      },
      "source": [
        "<p align=\"right\">فرض کنید می دانیم که داده های ما از یک توزیع گوسی پیروی می کنند و همچنین ویژگی ها از هم مستقل هستند لطفا با کمک فرض های مساله و بدون کمک از مدل های آماده یک مدل برای دسته بندی کلاس ها آموزش دهید . دقت کنید که نباید از کدهای آماده استفاده کنید و فقط مجاز هستید برای فرمول های پایه مثل میانگین یا واریانس از توابع آماده استفاده نمایید</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAlhGi06Voxt",
        "colab_type": "code",
        "outputId": "6e9ec693-49b2-42aa-9ce0-32dcfe025e6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "# training the model on training set \n",
        "\n",
        "# write your code here :\n",
        "\n",
        "# Calculate pc for each class\n",
        "pc = []\n",
        "\n",
        "pc.append(np.count_nonzero(y_train == 0)/len(y_train))\n",
        "pc.append(np.count_nonzero(y_train == 1)/len(y_train))\n",
        "pc.append(np.count_nonzero(y_train == 2)/len(y_train))\n",
        "\n",
        "print(pc)\n",
        "\n",
        "# Claculate m for each class \n",
        "\n",
        "m = []\n",
        "\n",
        "# 3 lists to store mean of each class\n",
        "a=[]\n",
        "b=[]\n",
        "c=[]\n",
        "\n",
        "for i in range(len(X_train)):\n",
        "  if y_train[i] == 0:\n",
        "    a.append(X_train[i])\n",
        "  elif y_train[i] == 1:\n",
        "    b.append(X_train[i])\n",
        "  else:\n",
        "    c.append(X_train[i])\n",
        "\n",
        "m.append(np.mean(a, axis=0))\n",
        "m.append(np.mean(b, axis=0))\n",
        "m.append(np.mean(c, axis=0))\n",
        "print(m)\n",
        "\n",
        "# Estimatin S parameter but we didnt use this method to reduce bias\n",
        "# s = []\n",
        "# s.append(np.std(a, axis=0))\n",
        "# s.append(np.std(b, axis=0))\n",
        "# s.append(np.std(c, axis=0))\n",
        "\n",
        "\n",
        "# Calculate s parameter\n",
        "\n",
        "s = [0, 0, 0]\n",
        "\n",
        "for x in a:\n",
        "  tmp = x-m[0]\n",
        "  tmpt = tmp.transpose()\n",
        "  s[0] += np.dot(tmp, tmpt)\n",
        "s[0] = s[0] / (len(a) - 1)\n",
        "for x in b:\n",
        "  tmp = x-m[1]\n",
        "  tmpt = tmp.transpose()\n",
        "  s[1] += np.dot(tmp, tmpt)\n",
        "s[1] = s[1] / (len(b) - 1)\n",
        "for x in c:\n",
        "  tmp = x-m[2]\n",
        "  tmpt = tmp.transpose()\n",
        "  s[2] += np.dot(tmp, tmpt)\n",
        "s[2] = s[2] / (len(c) - 1)\n",
        "print(s)\n",
        "\n",
        "# Calculate the discriminator function\n",
        "\n",
        "\n",
        "final = []\n",
        "for x in X_test:\n",
        "  \n",
        "  g = []\n",
        "  for i in range(len(s)):\n",
        "    g.append((-0.5*np.log(6.28)) - np.log(np.sqrt(s[i])) - np.divide(np.power(x-m[i], 2),(2*s[i])) + np.log(pc[i]))\n",
        "    \n",
        "  final.append(g)\n",
        "\n",
        "print(np.shape(final))\n",
        "\n",
        "discrim = []\n",
        "for objectt in final:\n",
        "  gg = []\n",
        "  for cllass in objectt:\n",
        "    tmp = np.prod(cllass)\n",
        "   \n",
        "    gg.append(tmp)\n",
        "  discrim.append(gg)\n",
        "\n",
        "print(np.shape(discrim))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.34444444444444444, 0.32222222222222224, 0.3333333333333333]\n",
            "[array([4.89677419, 3.33548387, 1.47096774, 0.23225806]), array([5.95862069, 2.70689655, 4.2137931 , 1.29310345]), array([6.38333333, 2.99666667, 5.41333333, 2.01666667])]\n",
            "[0.2937419354838709, 0.7115024630541874, 0.696126436781609]\n",
            "(60, 3, 4)\n",
            "(60, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkv9HCmSWAk0",
        "colab_type": "text"
      },
      "source": [
        "<p align=\"right\">اکنون با کمک داده های آزمایشی دقت مدل خود را بسنجید</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ordqnzrKXcLA",
        "colab_type": "code",
        "outputId": "d987552c-50e5-4566-c2b8-697ea71ae222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "#write your code here :\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "# predict classes for each x\n",
        "\n",
        "preds = []\n",
        "for x in discrim:\n",
        "  preds.append(x.index(np.min(x)))\n",
        "\n",
        "print(accuracy_score(y_test, preds))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V49EZ73XsvG",
        "colab_type": "text"
      },
      "source": [
        "# آموزش مدل بدون دانستن توزیع داده ها"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uni-0aA_X1ac",
        "colab_type": "text"
      },
      "source": [
        "<p align=\"right\">داده ها را با کمک دسته بند اس وی ام و همچنین یک شبکه عصبی ساده دسته بندی کنید و دقت را با بخش قبل مقایسه نمایید</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VftAlrbXZ-Nn",
        "colab_type": "code",
        "outputId": "e0ae7c22-7071-4023-e80d-15900eb1a636",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "#train svm model\n",
        "#write yor code here :\n",
        "\n",
        "c = svm.SVC()\n",
        "c.fit(X_train, y_train)\n",
        "\n",
        "preds = c.predict(X_test)\n",
        "\n",
        "print(accuracy_score(y_test, preds))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9833333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYJlUDsGaGQT",
        "colab_type": "code",
        "outputId": "9f6ab12b-2192-4f15-e0f6-b1c9b122b988",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        }
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "#use two hidden layers \n",
        "#train multi layer perceptron\n",
        "#write yor code here :\n",
        "c = MLPClassifier(hidden_layer_sizes=(64, 32))\n",
        "c.fit(X_train, y_train)\n",
        "\n",
        "preds = c.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, preds))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.86      0.92        28\n",
            "           1       0.90      0.96      0.93        27\n",
            "           2       0.84      0.94      0.89        17\n",
            "\n",
            "    accuracy                           0.92        72\n",
            "   macro avg       0.91      0.92      0.91        72\n",
            "weighted avg       0.92      0.92      0.92        72\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_bh4KyklqFA",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYGlkDuckgmz",
        "colab_type": "text"
      },
      "source": [
        "# خواندن داده های جدید"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d626_2ecknMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import datasets\n",
        "wine = datasets.load_wine()\n",
        "# store the feature matrix (X) and response vector (y) \n",
        "X = wine.data \n",
        "y = wine.target \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E3ihimJ_lBJq"
      },
      "source": [
        "# آموزش یک مدل با فرض گوسی بودن توزیع داد ها"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EIbuPy6GlKyw"
      },
      "source": [
        "<p align=\"right\">فرض کنید می دانیم که داده های ما از یک توزیع گوسی پیروی می کنند با کمک کتابخانه های آماده یک مدل برای دسته بندی کلاس ها آموزش دهید می  توانید برای این قسمت از کتابخانه های آماده نیز استفاده کنید و نیازی به پیاده سازی نیست</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2i8GbQt9lPJO",
        "outputId": "63d294c7-3d41-4f3d-91df-d4ac274b7c7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "# training the model on training set \n",
        "\n",
        "# write your code here :\n",
        "\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train, y_train)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9ugDovFDljq2"
      },
      "source": [
        "<p align=\"right\">اکنون با کمک داده های آزمایشی دقت مدل خود را بسنجید</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dnkJltLll0qD",
        "outputId": "b49c7e6e-f2aa-4444-889d-29305595b502",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "#write your code here :\n",
        "preds = clf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, preds))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98        28\n",
            "           1       1.00      0.96      0.98        27\n",
            "           2       1.00      1.00      1.00        17\n",
            "\n",
            "    accuracy                           0.99        72\n",
            "   macro avg       0.99      0.99      0.99        72\n",
            "weighted avg       0.99      0.99      0.99        72\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "24nscd6El30c"
      },
      "source": [
        "# آموزش مدل بدون دانستن توزیع داده ها"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jXoB6ppJl7Vl"
      },
      "source": [
        "<p align=\"right\">داده ها را با کمک دسته بند اس وی ام و همچنین یک شبکه عصبی ساده دسته بندی کنید و دقت را با بخش قبل مقایسه نمایید</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9cw27u1bmBWE",
        "outputId": "26b94e89-12cd-472d-cff5-58a99a3d4aba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "#train svm model\n",
        "#write yor code here :\n",
        "c = svm.SVC()\n",
        "c.fit(X_train, y_train)\n",
        "\n",
        "preds = c.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, preds))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.86      0.89        28\n",
            "           1       0.65      0.81      0.72        27\n",
            "           2       0.42      0.29      0.34        17\n",
            "\n",
            "    accuracy                           0.71        72\n",
            "   macro avg       0.66      0.66      0.65        72\n",
            "weighted avg       0.70      0.71      0.70        72\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tqS7kFEqmEMG",
        "outputId": "a74c6d09-fb28-4602-8ccf-ecf5ac36282e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        }
      },
      "source": [
        "#train multi layer perceptron\n",
        "#write yor code here\n",
        "\n",
        "c = MLPClassifier(hidden_layer_sizes=(128, 64))\n",
        "c.fit(X_train, y_train)\n",
        "\n",
        "preds = c.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, preds))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94        28\n",
            "           1       0.84      1.00      0.92        27\n",
            "           2       1.00      0.88      0.94        17\n",
            "\n",
            "    accuracy                           0.93        72\n",
            "   macro avg       0.95      0.93      0.93        72\n",
            "weighted avg       0.94      0.93      0.93        72\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xw54ZdjmlsjN",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_qYfi-kgFbN",
        "colab_type": "text"
      },
      "source": [
        "#بخش امتیازی"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ97VUicmoir",
        "colab_type": "text"
      },
      "source": [
        "<p align=\"right\">آیا راهی وجود دارد که قبل از انتخاب بک دسته بند بتوان توزیع یک داده را حدس زد و دسته بندی را بر اساس این بینش از داده ها انجام داد؟</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Oi6thGwnNiC",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}